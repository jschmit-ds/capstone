{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d59001",
   "metadata": {},
   "source": [
    "# Time Series Prediction with LSTM Using PyTorch\n",
    "In this notebook we will use PyTorch to build an LSTM model to help us forecast the number of traffic collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ddda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import boto3\n",
    "import awswrangler\n",
    "# set name of S3 bucket\n",
    "s3_bucket = 'traffic-data-bucket'\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "\n",
    "path =  Path(os.getcwd())\n",
    "root = path.parent.absolute()\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60250cb-f08f-4573-84f0-3ad4fa87c7cb",
   "metadata": {},
   "source": [
    "## 1. Connect to AWS Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9d007-f70c-4cbb-9734-5eb95ba5dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_secrets import aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "\n",
    "my_session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    aws_session_token = aws_session_token\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f73171",
   "metadata": {},
   "source": [
    "## 2. Import data from S3\n",
    "AWS Wrangler is used to read all files in the S3 Bucket with a .csv suffix into a single Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ae205",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path_dir = 'TIMS_raw_crashes/'\n",
    "\n",
    "# path of S3 bucket where collision data is stored\n",
    "raw_path = f\"s3://{s3_bucket}/{raw_path_dir}\"\n",
    "\n",
    "# read data from S3 bucket\n",
    "collision_df = awswrangler.s3.read_csv(path=raw_path, path_suffix=['.csv'], dataset=True,\n",
    "                                 boto3_session=my_session, use_threads=True, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741737c8-ea04-42c4-94a8-8b061b71b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d73fe9-9c60-4ea5-9de2-fc0a8a719d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of collisions:', collision_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3766ee-0589-437c-bab1-b23a4e12833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(collision_df['ACCIDENT_YEAR'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56fd63-a249-4028-a051-f1cc4bf1f988",
   "metadata": {},
   "source": [
    "We can see that our dataset contains records for years 2014 to 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d58b8-7465-4ba8-8485-eb154659c520",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb773a3-acdf-44b5-8bc7-a67009841225",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_df[['ACCIDENT_YEAR','COLLISION_DATE']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355215f-97df-4eaf-b52d-2d926d8fdb6b",
   "metadata": {},
   "source": [
    "Convert collision date to datetime type and extract the year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44e32e-e341-464f-842c-0c470743e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_df['COLLISION_DATE'] = collision_df['COLLISION_DATE'].astype('datetime64[ns]')\n",
    "collision_df['Year-Month'] = collision_df['COLLISION_DATE'].dt.strftime('%Y-%m')\n",
    "collision_df['Year-Week'] = collision_df['COLLISION_DATE'].dt.strftime('%Y-%U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a08344-b9cd-4a61-8e8e-dc3e37413d61",
   "metadata": {},
   "source": [
    "Next, we group by the collision date to count the number of accidents by year-month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe79e2-a05f-4b9e-9bb9-14260fe89357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collision_df.groupby(['Year-Week','ACCIDENT_YEAR'], as_index=False)['CASE_ID'].count()\n",
    "df.rename(columns={'CASE_ID':'Accidents','ACCIDENT_YEAR':'Accident_Year'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed09fd7-e1ef-44fa-854e-066e0bea6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aefc3d-183e-4fd7-a14b-8b9c649e29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed24cf5-0a40-4d75-933a-9f189af6c2f2",
   "metadata": {},
   "source": [
    "Let's create a simple chart to visualize the number of monthly collisions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65ad35-38be-45af-9abc-48ee3e4cac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X('Year-Week:T', axis=alt.Axis(grid=False)),\n",
    "    y=alt.Y('Accidents:Q', axis=alt.Axis(grid=False))\n",
    ").properties(width=600, title='2014 to 2021 Collisions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68464c3f-a96e-46d5-a807-2fc1de91427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = df[df['Accident_Year'] <= 2019]\n",
    "# test_set = df[df['Accident_Year'] >= 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d3a3e-3d79-4b8d-b18a-a56d58c2da10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select features and perform feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35e887-5754-46cc-ae58-85efb75a34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = df['Accidents'].values.reshape(-1, 1)\n",
    "\n",
    "training_data = df.iloc[:,2:3].values\n",
    "\n",
    "# scale features\n",
    "sc = MinMaxScaler()\n",
    "training_data = sc.fit_transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b57d0-0730-447d-975c-06a000f52cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e55c11-b17c-4193-94a4-51e5db3585e5",
   "metadata": {},
   "source": [
    "### Define a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e9362-0353-4782-b986-9dfd31cf0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05e8c-badc-4400-82e9-e8911957ccf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split data into train and test sets\n",
    "The training set will contain years 2014 through 2019 and the test set will serve as the held-out test validation set by containing years 2020 and 2021.  There are 72 months in years 2014 through 2019 so the training set will be based on the first 72 values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def36c0-70f9-470d-8f75-a8817abc11f5",
   "metadata": {},
   "source": [
    "## 4-week window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae82bfe-c36f-42f2-9f96-8675f9fb1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 4\n",
    "# apply sliding window\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "# split the data into train test sets\n",
    "train_size = int(len(y) * 0.74)\n",
    "test_size = len(y) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b6f06-3de6-444e-be3f-4add105ca90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of months in training set:', train_size)\n",
    "print('Number of months in test set:', test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4f4be-9f41-42bb-8f03-27f7607ffc69",
   "metadata": {},
   "source": [
    "### Convert training data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310868fc-179a-4ab9-81e2-000ae9e10d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = Variable(torch.Tensor(np.array(x)))\n",
    "dataY = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
    "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
    "\n",
    "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
    "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb29292-0347-4053-85c2-70a3e25e0329",
   "metadata": {},
   "source": [
    "## 4. Build LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec079a-7ab2-45d0-b85a-b6d2885f5f7c",
   "metadata": {},
   "source": [
    "### Define the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc4728-0f81-4ae0-a97b-f77f543652b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c450b0-9874-4f65-b18d-3bf66d1b5516",
   "metadata": {},
   "source": [
    "## 5. Model training\n",
    "### 5.1 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd19280-eaa4-48d8-b05a-cf52d16b608b",
   "metadata": {},
   "source": [
    "Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7080846-064e-4e94-86e8-5f40717eb2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37317e6e-e659-4168-a106-7858d465d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 8000\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58ea9b-a82e-41a4-b75e-92293dd1b279",
   "metadata": {},
   "source": [
    "### 5.2 Generate predictions and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98900086-1493-4181-a977-a188a4c3e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "actuals_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "actuals_plot = sc.inverse_transform(actuals_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03d04b-0cbf-4f6f-a141-59fb96958d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd067cce-6494-4d1e-8e60-116591a11a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(actuals_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fe36f-9ede-4d39-a5a5-5374eb5433e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.axvline(x=train_size, c='blue', linestyle='--')\n",
    "plt.plot(actuals_plot, label='Acutals')\n",
    "plt.plot(data_predict, label='Predictions')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(0, 1500)\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
