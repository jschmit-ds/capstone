{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML Using AutoGluon\n",
    "### Notebook Setup\n",
    "- Select instance size:  ml.m5.4xlarge (16vCPU + 64GB)\n",
    "- Install the following libraries\n",
    "\n",
    "### AutoML Training Approach\n",
    "The AutoML training will be applied using three different approaches using different training criteria within each approach.\n",
    "- **Model1:**  baseline model using 50% of training data and excluding KNN and neural network models\n",
    "- **Model2:**  advanced training using 50% of training data with hyper parameter optimization and including neural network models\n",
    "- **Model3:**  the best performing approach from model 1 and model 2 will be selected to train on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pip\n",
    "# !pip install -U setuptools wheel\n",
    "# !pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "# !pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import altair as alt\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# set name of S3 bucket\n",
    "s3_bucket = 'traffic-data-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://traffic-data-bucket/model_data/model_data_post_transformation.parquet', engine='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "### 2.1 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = df.isnull().sum() / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "missing_value_df.sort_values('percent_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Drop years 2014\n",
    "2014 will be dropped from the dataset due to some features such as prior year collisions not being available for year 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['collision_year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['collision_year'] != 2014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature selection\n",
    "Feature selection will take place by selecting features based on the following categories:\n",
    "- Street\n",
    "- Time and date\n",
    "- Hexagon\n",
    "- Weather\n",
    "\n",
    "#### Angular distance for day of the week\n",
    "The day of the week is currently a numeric feature but Saturday is closer to Monday than Wednesday so in order to capture the circular nature of weeks and teh actual distance between days, we will calculate the cosine and sine values of the degree. We will also convert the month to a categorical variable to see if that changes performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week_sin'] = np.sin(df['collision_dayofweek'] * (2 * np.pi / 7))\n",
    "df['day_of_week_cos'] = np.cos(df['collision_dayofweek'] * (2 * np.pi / 7))\n",
    "df.drop('collision_dayofweek', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_features = ['la_data_city_name', \n",
    "                     'node_street_count', 'node_stop', 'node_traffic_signals',\n",
    "                     'edge_speed_kph_max', 'edge_speek_kph_min',\n",
    "                     'edge_lanes_max', 'edge_motorway_flag', 'edge_motorway_link_flag',\n",
    "                     'edge_living_street_flag', 'edge_bridge_flag', 'edge_oneway_flag',\n",
    "                     'edge_tunnel_flag', 'amenities_bar_cnt', 'amenities_school_cnt',\n",
    "                     'amenities_restaurant_cnt', 'amenities_college_cnt',\n",
    "                     'drv_edge_lanes_max_imputed_flag']\n",
    "\n",
    "time_features = ['drv_collision_hour_sin','drv_collision_hour_cos',\n",
    "                 'collision_month', 'drv_holiday_flag', 'day_of_week_sin', 'day_of_week_cos' # add cosine and sine for day of the week\n",
    "                ]\n",
    "\n",
    "hex_history_features = ['prev1_yr_coll_cnt', 'prev1_yr_coll_neighbor1']\n",
    "\n",
    "weather_features = ['noaa_wind_speed', 'noaa_precipitation',\n",
    "                    'noaa_temperature_average', 'noaa_temperature_max',\n",
    "                    'noaa_temperature_min']\n",
    "\n",
    "# include the target\n",
    "model_features = street_features +  time_features + hex_history_features +  weather_features + ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Feature encoding\n",
    "Review data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[model_features].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon does not recognize `Int64` or `Float64` data types so these columns need to be converted to `int64` and `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'Int64':\n",
    "        df[column] = df[column].astype(int)\n",
    "    if df[column].dtype == 'Float64':\n",
    "        df[column] = df[column].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the city name as category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of cities in Los Angeles County:', df['la_data_city_name'].nunique())\n",
    "df['la_data_city_name'] = df['la_data_city_name'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract the previous year collision count from the previous year collision neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev1_yr_coll_neighbor1'] = df['prev1_yr_coll_neighbor1'] - df['prev1_yr_coll_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[model_features].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Split data into train-test-validation and drop 2020 data from train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'target'\n",
    "\n",
    "# training set with target\n",
    "df_train = df[df['ttv_split'] == 'Train']\n",
    "df_train = df_train[df_train['collision_year'] != 2020][model_features]\n",
    "\n",
    "# test set for model tuning\n",
    "df_test = df[df['ttv_split'] == 'Test']\n",
    "df_test = df_test[df_test['collision_year'] != 2020][model_features]\n",
    "\n",
    "# all data for model predictions containing 2020 data\n",
    "df_all = df.copy()\n",
    "df_all = df_all[model_features]\n",
    "\n",
    "# target \n",
    "y_train = df_train[label]\n",
    "y_test = df_test[label]\n",
    "\n",
    "# drop target label\n",
    "X_train = df_train.drop(columns=[label])\n",
    "X_test = df_test.drop(columns=[label])\n",
    "X_all = df_all.drop(columns=[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution between the negative (0) and positive (1) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('target', as_index=False)['target'].count().plot(kind='bar', title='Distribution of target class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create a sample dataset using 50% of data for initial training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = df_train.sample(frac =.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training\n",
    "The training approach will be to train three different models using different training criteria.\n",
    "- **Model1:**  baseline model using 50% of training data and excluding KNN and neural network models\n",
    "- **Model2:**  advanced training using 50% of training data with hyper parameter optimization and including neural network models\n",
    "- **Model3:**  the best performing approach from model 1 and model 2 will be selected to train on the entire training set\n",
    "\n",
    "If you already have a model saved you can load it into the predictor to save on training.  Uncomment the cell below if you have a model saved that you'd like to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # where the model is stored\n",
    "# load_path = 'agModels-baseModel_updated'\n",
    "# # load into the predictor\n",
    "# predictor = TabularPredictor.load(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Baseline model using sample subset data\n",
    "This model will be trained on 50% of the training data and does not include any feature encoding and does not train on any KNN or Neural Network models.\n",
    "- Training time: 10 minutes\n",
    "- No hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose where to store the model\n",
    "save_path = 'agModels-base_model'\n",
    "\n",
    "# select training data\n",
    "training_data = df_train_sample\n",
    "\n",
    "# set training time\n",
    "training_time = 10*60\n",
    "\n",
    "# set quality of models\n",
    "model_quality = 'best_quality'\n",
    "\n",
    "# model classes to be excluded from training\n",
    "excluded_model_types = ['KNN', 'NN_TORCH']\n",
    "\n",
    "predictor = TabularPredictor(label=\"target\", problem_type = 'binary', eval_metric='roc_auc', learner_kwargs={'positive_class':1}, path=save_path\n",
    "                            ).fit(train_data=training_data, time_limit=training_time, presets=model_quality, excluded_model_types=excluded_model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Generate leaderboard of ranking model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_leaderboard = predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to output a chart that shows the scores for the various trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaderboard_chart(leaderboard, title, subtitle, color_scheme):\n",
    "    '''\n",
    "    Arguments:\n",
    "        title: title of the chart in string format\n",
    "        subtitle: subtitle of the chart in string format\n",
    "        leaderboard: predictor leaderboard object\n",
    "        color_scheme: Altair color scheme\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create base chart\n",
    "    base = alt.Chart(leaderboard).mark_bar(size=10).encode(\n",
    "        x=alt.X('model:N', axis=alt.Axis(title='Model'), sort='-y'),\n",
    "        y=alt.Y('score_val:Q', axis=alt.Axis(title='ROC and AUC Score', format=\",.2f\"), scale=alt.Scale(domain=(0,1.0)))\n",
    "    )\n",
    "\n",
    "    # apply color to bars only\n",
    "    bars = base.mark_bar().encode(\n",
    "        color=alt.Color('score_val:Q', legend=None, scale=alt.Scale(scheme=color_scheme))\n",
    "    )\n",
    "\n",
    "    # lay text over base chart\n",
    "    text = base.mark_text(\n",
    "        align='center',\n",
    "        baseline='middle',\n",
    "        dy=-10  # Nudges text to right so it doesn't appear on top of the bar\n",
    "    ).encode(\n",
    "        text=alt.Text('score_val:Q', format=\",.3f\")\n",
    "    )\n",
    "\n",
    "    # combine all charts\n",
    "    combined_chart = (bars + text).properties(width=700, title={'text':[title],\n",
    "                                               'subtitle':[subtitle,''],\n",
    "                                               'subtitleFont':'Segoe UI',\n",
    "                                               'subtitleFontSize':14\n",
    "                                              }).configure_axis(\n",
    "        grid=False, # remove gridlines\n",
    "    ).configure_title(\n",
    "        anchor='start',\n",
    "        fontSize=20\n",
    "    )\n",
    "    \n",
    "    return combined_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_chart(baseline_leaderboard, 'Model 1 Performance', 'Training done on 50% of data using AutoGluon and no hyper parameter optimization','tealblues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Predict probabilities on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .predict method to create predictions on test set\n",
    "y_pred = predictor.predict_proba(X_test)\n",
    "# print(\"Predictions:  \\n\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Evaluate predictions against ground truth using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_baseline_model = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n",
    "perf_baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Generate predictions on the entire dataset and upload to S3\n",
    "Let's start by creating a function that returns predictions for `df_all` which represents the entire dataset and years 2015 to 2020.  The year 2014 was dropped during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_df(model_name, prediction_values):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name:  name of the model\n",
    "        prediction_values: predictions generated using .predict_proba or .predict\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with predictions to be used for model scoring\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    df['model_name'] = model_name\n",
    "    df['prediction'] = prediction_values[1]\n",
    "    \n",
    "    df_predictions = df[['hex_id', 'collision_date', 'collision_hour', 'ttv_split', 'prediction', 'model_name']]\n",
    "    \n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict_proba(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = predictions_df('AutoGluon_Baseline', predictions)\n",
    "\n",
    "df_output.to_csv(f\"s3://{s3_bucket}/model_scoring/individual_model_scores/AutoGluon_Baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Model w/manually selected hyperparameters\n",
    "#### 3.2.1 Perform one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new datasets to store one-hot encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_train_sample = df_train_sample.copy()\n",
    "transformed_X_test = X_test.copy()\n",
    "transformed_X_all = X_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "transformed = ohe.fit_transform(transformed_df_train_sample[['la_data_city_name']])\n",
    "# add transformed columns back to dataframe\n",
    "transformed_df_train_sample[ohe.categories_[0]] = transformed.toarray()\n",
    "transformed_df_train_sample.drop('la_data_city_name', axis=1, inplace=True)\n",
    "\n",
    "# apply the same transformation to the test set\n",
    "transformed = ohe.fit_transform(transformed_X_test[['la_data_city_name']])\n",
    "# add transformed columns back to dataframe\n",
    "transformed_X_test[ohe.categories_[0]] = transformed.toarray()\n",
    "transformed_X_test.drop('la_data_city_name', axis=1, inplace=True)\n",
    "\n",
    "# apply the same transformation to validation dataframe\n",
    "transformed = ohe.fit_transform(transformed_X_all[['la_data_city_name']])\n",
    "# add transformed columns back to dataframe\n",
    "transformed_X_all[ohe.categories_[0]] = transformed.toarray()\n",
    "transformed_X_all.drop('la_data_city_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Define hyper parameters and train model\n",
    "- Model types trained:  Neural network, GBM, XGB\n",
    "- Training data:  sample subset\n",
    "- Training time: 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "# neural network hyper parameters\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "# gbm hyper parameters\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "# xgb hyper parameters\n",
    "xgb_options = {'n_estimators': 1000, 'learning_rate': ag.Real(0.01, 0.1, log=True)}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                    'XGB':xgb_options}  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~10 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform training on one-hot encoded sample training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'agModels-hpo_model'\n",
    "\n",
    "training_data = transformed_df_train_sample\n",
    "\n",
    "\n",
    "# set quality of models\n",
    "model_quality = 'best_quality'\n",
    "\n",
    "hpo_predictor = TabularPredictor(label=\"target\", problem_type = 'binary', eval_metric='roc_auc', learner_kwargs={'positive_class':1}, path=save_path\n",
    "                            ).fit(train_data=training_data, time_limit=time_limit, num_stack_levels=2,\n",
    "                                  presets=model_quality, hyperparameters=hyperparameters,\n",
    "                                  hyperparameter_tune_kwargs=hyperparameter_tune_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_leaderboard = hpo_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Predict probabilities on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .predict method to create predictions on test set\n",
    "y_pred = hpo_predictor.predict_proba(transformed_X_test)\n",
    "# print(\"Predictions:  \\n\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Evaluate predictions against ground truth using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_hpo_model = hpo_predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Generate predictions on the entire dataset\n",
    "Let's start by creating a function that returns predictions for `df_all` which represents the entire dataset and years 2015 to 2020.  The year 2014 was dropped during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = hpo_predictor.predict_proba(transformed_X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Output a dataframe of predictions for the entire dataset and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = predictions_df('AutoGluon_HPO', predictions)\n",
    "\n",
    "df_output.to_csv(f\"s3://{s3_bucket}/model_scoring/individual_model_scores/AutoGluon_HPO.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_baseline = hpo_predictor.feature_importance(data=transformed_df_train_sample, subsample_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_baseline.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Final model\n",
    "Our model didn't seem to improve after performing manually selecting hyperparameters or with one-hot encoding.  The WeightedEnsemble_L2 model came on top again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose where to store the model\n",
    "save_path = 'agModels-final_model_updated'\n",
    "\n",
    "training_data = df_train\n",
    "\n",
    "# set quality of models\n",
    "model_quality = 'best_quality'\n",
    "\n",
    "# model classes to be excluded from training\n",
    "excluded_model_types = ['KNN']\n",
    "\n",
    "training_time = 15*60\n",
    "\n",
    "full_training_predictor = TabularPredictor(label=\"target\", problem_type = 'binary', eval_metric='roc_auc', learner_kwargs={'positive_class':1}, path=save_path\n",
    "                            ).fit(train_data=training_data, time_limit=training_time, presets=model_quality, excluded_model_types=excluded_model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_leaderboard = full_training_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create leaderboard plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_chart(full_training_leaderboard, 'AutoGluon Performance', 'Training done on 100% of data','tealblues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_training_predictor.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_full_model = full_training_predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate predictions on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_training_predictor.predict_proba(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = predictions_df('AutoGluon_Full_Training', predictions)\n",
    "\n",
    "df_output.to_csv(f\"s3://{s3_bucket}/model_scoring/individual_model_scores/AutoGluon_Full_Training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explain Predictions and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('postiive class:', full_training_predictor.positive_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutogluonWrapper:\n",
    "    def __init__(self, predictor, feature_names):\n",
    "        self.ag_model = predictor\n",
    "        self.feature_names = feature_names\n",
    "    \n",
    "    def predict_binary_prob(self, X):\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.values.reshape(1,-1)\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.feature_names)\n",
    "        return self.ag_model.predict_proba(X, as_multiclass=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mode across all columns in X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_df = X_train.mode()  # X_train.mode() would be a more appropriate baseline for ordinally-encoded categorical features\n",
    "mode_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get feature names from X_train and create a KernelExplainer that returns a Kernsl SHAP values to explain particular AutoGluon predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "# use the full training predictor\n",
    "ag_wrapper = AutogluonWrapper(full_training_predictor, feature_names)\n",
    "explainer = shap.KernelExplainer(ag_wrapper.predict_binary_prob, mode_df)\n",
    "\n",
    "NSHAP_SAMPLES = 100  # how many samples to use to approximate each Shapely value, larger values will be slower\n",
    "N_VAL = 50  # how many datapoints from validation data should we interpret predictions for, larger values will be slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SHAP values aggregated across the first n datapoints of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_all.iloc[0:N_VAL], nsamples=NSHAP_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_all.iloc[:N_VAL,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_all.iloc[:N_VAL,:], plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.9 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/mxnet-1.9-cpu-py38-ubuntu20.04-sagemaker-v1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
